{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3 - Reducción de dimensionalidad\n",
    "\n",
    "__Curso__: Statistical Learning II\n",
    "\n",
    "__Catedrático__: Ing. Luis Leal\n",
    "\n",
    "__Estudiante__: Dany Rafael Díaz Lux (21000864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías que utilizaremos\n",
    "#from scipy.stats import multivariate_normal\n",
    "#from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y escalar información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imágenes de fashion mnist\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(imagenes_train, etiquetas_train), (imagenes_test, etiquetas_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de imágenes\n",
      "(70000, 784)\n",
      "[[-0.00883265 -0.02162585 -0.0287172  ... -0.15825699 -0.09035386\n",
      "  -0.03423352]\n",
      " [-0.00883265 -0.02162585 -0.0287172  ... -0.15825699 -0.09035386\n",
      "  -0.03423352]\n",
      " [-0.00883265 -0.02162585 -0.0287172  ... -0.15825699 -0.09035386\n",
      "  -0.03423352]\n",
      " [-0.00883265 -0.02162585 -0.0287172  ... -0.15825699 -0.09035386\n",
      "  -0.03423352]\n",
      " [-0.00883265 -0.02162585 -0.0287172  ... -0.15825699 -0.09035386\n",
      "  -0.03423352]]\n",
      "Número de etiquetas\n",
      "(70000,)\n",
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "# Pasar de matrices de 28x28 a vectores de 784.\n",
    "imagenesPlanas = imagenes_train.reshape(imagenes_train.shape[0], imagenes_train.shape[1] * imagenes_train.shape[2])\n",
    "imagenesPlanas = np.append(imagenesPlanas, \\\n",
    "                           imagenes_test.reshape(imagenes_test.shape[0], imagenes_test.shape[1] * imagenes_test.shape[2]), axis= 0)\n",
    "etiquetas = np.append(etiquetas_train, etiquetas_test)\n",
    "# Estandarizar información\n",
    "estandarizadorImagenes = StandardScaler()\n",
    "imagenesPlanas = estandarizadorImagenes.fit_transform(imagenesPlanas)\n",
    "print('Dimensiones de imágenes')\n",
    "print(imagenesPlanas.shape)\n",
    "print(imagenesPlanas[0:5,:])\n",
    "print('Número de etiquetas')\n",
    "print(etiquetas.shape)\n",
    "print(etiquetas[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de componentes principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = np.array([[4, 2, 1, 3], [7, 4, 2, 6], [10, 6, 3, 9], [24, 20, 10, 30], [18, 14, 7, 21]])\n",
    "#cov = np.cov(test.T)\n",
    "#print(cov)\n",
    "#vals, vecs = np.linalg.eig(cov)\n",
    "#print(vals)\n",
    "#indices = np.argsort(-np.abs(vals))[0:2]\n",
    "#print(indices)\n",
    "#print(vecs)\n",
    "#print(vecs[:,indices])\n",
    "#from sklearn.decomposition import PCA\n",
    "#np.random.seed(0)\n",
    "#my_matrix = np.random.randn(20,5)\n",
    "#cov = np.cov(my_matrix.T)\n",
    "#print(cov.diagonal())\n",
    "#print(cov.diagonal()/np.sum(cov.diagonal()))\n",
    "#my_model = PCA(n_components=5)\n",
    "#my_model.fit_transform(my_matrix)\n",
    "#print(my_model.explained_variance_ratio_)\n",
    "#print(np.sum(np.abs(vals)))\n",
    "#test2 = sorted(vals, reverse=True)/np.sum(vals)\n",
    "#print(test2.T)\n",
    "#print(vals)\n",
    "#total_egnvalues = sum(vals)\n",
    "#var_exp = np.array([(i/total_egnvalues) for i in sorted(vals, reverse=True)])\n",
    "#print(var_exp)\n",
    "#print(var_exp.cumsum()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que devolverá la matriz de \"k\" dimensiones reducida para X\n",
    "def obtenerMatrizReducidaPCA(X, k):\n",
    "    if(k < 1 or k > X.shape[1]):\n",
    "        print('Error enviado en el número de dimensiones que se desea preservar k: ', k)\n",
    "        return None\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)\n",
    "    # Obtener matriz de covarianza\n",
    "    matrizCovarianza = np.cov(X.T)\n",
    "    # Obtener eigen-values y eigen-vectors\n",
    "    eigenVals, eigenVecs = np.linalg.eig(matrizCovarianza)\n",
    "    # Determinar cantidad de información preservada\n",
    "    varianzaPreservada = sorted(eigenVals, reverse=True)/np.sum(eigenVals)\n",
    "    informacionPreservada = varianzaPreservada.cumsum()[k-1]\n",
    "    # Determinar los índices de los \"k\" eigen-values con valores absolutos más grandes.\n",
    "    indices = np.argsort(-np.abs(eigenVals))[0:k]\n",
    "    # Devolver la matriz con los k eigen vectors\n",
    "    return eigenVecs[:,indices], informacionPreservada\n",
    "\n",
    "# Función para transformar información en dimensiones reducidas\n",
    "def transformarConMatrizReducidaPCA(X, matrizReducida):\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)\n",
    "    if(type(matrizReducida).__module__ != np.__name__):\n",
    "        matrizReducida = np.array(matrizReducida)\n",
    "    # Asegurarse que el número de características sean las columnas de X y el número de filas de matrizReducida\n",
    "    if(X.shape[1] == matrizReducida.shape[0]):\n",
    "        return np.matmul(X, matrizReducida)\n",
    "    print('Error en las dimensiones de las matrices')\n",
    "    print('Forma de datos')\n",
    "    print(X.shape)\n",
    "    print('Forma matriz reducida')\n",
    "    print(matrizReducida.shape)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-Distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerModeloTsne(X, k):\n",
    "    return TSNE(n_components=k, random_state=2022).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducir información a 2 dimensiones con PCA y t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representación imágenes reducidas con PCA\n",
      "(10000, 2)\n",
      "[[ -0.98941186 -20.75232521]\n",
      " [ 17.00505454   4.87364139]\n",
      " [ -9.49313162  12.41609182]\n",
      " ...\n",
      " [ 13.45476333   7.77806339]\n",
      " [ -2.94757494  11.08942227]\n",
      " [ 11.72563831  -5.26358477]]\n",
      "Información preservada con PCA\n",
      "0.35810306937433095\n"
     ]
    }
   ],
   "source": [
    "# Se realizarán sólo las primeras 10,000 por cuestiones de tiempo\n",
    "# Reducir con PCA\n",
    "matrizReducida, informacionPreservada = obtenerMatrizReducidaPCA(imagenesPlanas[0:10000,:], 2)\n",
    "imagenesReducidasConPCA = transformarConMatrizReducidaPCA(imagenesPlanas[0:10000,:], matrizReducida)\n",
    "print('Representación imágenes reducidas con PCA')\n",
    "print(imagenesReducidasConPCA.shape)\n",
    "print(imagenesReducidasConPCA)\n",
    "print('Información preservada con PCA')\n",
    "print(informacionPreservada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representación imágenes reducidas con t-SNE\n",
      "(10000, 2)\n",
      "[[ 59.906467  -20.277704 ]\n",
      " [-39.80932    37.376087 ]\n",
      " [-20.463747   -2.8083603]\n",
      " ...\n",
      " [-47.898346    7.2352967]\n",
      " [-21.387966   20.682526 ]\n",
      " [ 18.58468    34.523937 ]]\n"
     ]
    }
   ],
   "source": [
    "# Se realizarán sólo las primeras 10,000 por cuestiones de tiempo\n",
    "imagenesReducidasTsne = obtenerModeloTsne(imagenesPlanas[0:10000,:], 2)\n",
    "print('Representación imágenes reducidas con t-SNE')\n",
    "print(imagenesReducidasTsne.shape)\n",
    "print(imagenesReducidasTsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios en reducción de dimensionalidad con PCA y t-SNE\n",
    "\n",
    "* Las representaciones no muestran ningún tipo de similitud numérica (al menos no las desplegadas en notebook).\n",
    "* Para PCA, la varianza conservada es de 35.81% que es mucha más de la que se esperaba dado que se redujo de 784 a 2 dimensiones.\n",
    "* Para este caso específico de reducción de 784 a 2 dimensiones, el método de PCA implementado manualmente, fue más rápido que el método de t-SNE implementado por scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar clustering con GMM sobre representaciones reducidas (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0 2 7 2 5 5]\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "print(etiquetas[0:10])\n",
    "print(len(etiquetas[etiquetas == 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para crear un modelo Gaussian Mixture Model\n",
    "def obtenerGMM(X, k):\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)    \n",
    "    if(k < X.shape[0]):\n",
    "        return GaussianMixture(n_components=k, random_state=2022).fit(X)\n",
    "    else:\n",
    "        print('k debe ser menor al número de observaciones en X.')\n",
    "        return None\n",
    "    \n",
    "# Función que evaluará la \"exactitud\" de los clusters con las etiquetas\n",
    "# Aspectos que tomará en cuenta\n",
    "# 1. % de cluster que más aparece en una etiqueta.\n",
    "# 2. Si el cluster ya ha sido escogido en otra etiqueta anterior, ese cluster tendrá una exactitud del 0%\n",
    "# 3. Se devolverá porcentaje por cada etiqueta.\n",
    "def calcularExactitudClusters(predicciones, etiquetas):\n",
    "    etiquetasUnicas = np.unique(etiquetas)\n",
    "    exactitudes = np.zeros(etiquetasUnicas.shape[0])\n",
    "    prediccionesUtilizadas = []\n",
    "    for iEtiqueta, etiquetaUnica in enumerate(etiquetasUnicas):\n",
    "        indicesEtiqueta = np.argwhere(etiquetas == etiquetaUnica)\n",
    "        prediccionesEnEtiqueta = predicciones[indicesEtiqueta]\n",
    "        moda = stats.mode(prediccionesEnEtiqueta)[0][0]\n",
    "        # Agregar moda obtenida en predicciones utilizadas\n",
    "        if(moda not in prediccionesUtilizadas):\n",
    "            prediccionesUtilizadas.append(moda)\n",
    "            exactitudes[iEtiqueta] = (len(prediccionesEnEtiqueta[prediccionesEnEtiqueta == moda]) / len(prediccionesEnEtiqueta))\n",
    "        else:\n",
    "            exactitudes[iEtiqueta] = 0.0\n",
    "    return exactitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de exactitud obtenido de los clusters con datos con dimensionalidad reducida con PCA:\n",
      "0.39064800076142137\n",
      "Promedio de exactitud obtenido de los clusters con datos con dimensionalidad reducida con t-SNE:\n",
      "0.5178117204311274\n"
     ]
    }
   ],
   "source": [
    "# Para PCA\n",
    "modeloGMM = obtenerGMM(imagenesReducidasConPCA, 10)\n",
    "exactitudes = calcularExactitudClusters(modeloGMM.predict(imagenesReducidasConPCA), etiquetas[0:10000])\n",
    "print('Promedio de exactitud obtenido de los clusters con datos con dimensionalidad reducida con PCA:')\n",
    "print(np.mean(exactitudes))\n",
    "# Para t-SNE\n",
    "modeloGMM = obtenerGMM(imagenesReducidasTsne, 10)\n",
    "exactitudes = calcularExactitudClusters(modeloGMM.predict(imagenesReducidasTsne), etiquetas[0:10000])\n",
    "print('Promedio de exactitud obtenido de los clusters con datos con dimensionalidad reducida con t-SNE:')\n",
    "print(np.mean(exactitudes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "* La exactitud (definida en los comentarios de la función) de los clusters para los datos reducidos con PCA fue de un 39.06%.\n",
    "* La exactitud de los clusters para los datos reducidos con t-SNE fue de un 51.78%\n",
    "* Dado que se pasó de 784 a 2 dimensiones, las métricas de exactitud parecen bastante altas al tomar en cuenta la gran diferencia en reducción de dimensionalidad que se llevó a cabo.\n",
    "* Se puede observar cierto acercamiento con la cantidad de varianza preservada con la definición de exactitud definida en la función para el método de PCA. Más experimentación sería necesaria para determinar si existe una correlación fuerte entre ambas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
