{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2 - Detección de anomalías\n",
    "\n",
    "__Curso__: Statistical Learning II\n",
    "\n",
    "__Catedrático__: Ing. Luis Leal\n",
    "\n",
    "__Estudiante__: Dany Rafael Díaz Lux (21000864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías que utilizaremos\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y escalar información de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61336991 -0.60120511]\n",
      " [ 0.207922    0.16881129]\n",
      " [-0.0623766  -0.90921166]\n",
      " [ 0.74851921  0.63082112]\n",
      " [-1.00842171  0.32281456]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar información de estaturas\n",
    "estaturasDf = pd.read_excel('estaturas.xlsx', sheet_name='normales')\n",
    "# Estandarizar información\n",
    "estaturasScaler = StandardScaler()\n",
    "estaturasEstandarizadas = estaturasScaler.fit_transform(estaturasDf)\n",
    "# Mostrar primeros datos estandarizados\n",
    "print(estaturasEstandarizadas[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para determinar densidad de probabilidad para datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para determinar las medias y varianzas de los datos\n",
    "def obtenerMediasyMatrizCovarianza(X):\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)\n",
    "    \n",
    "    media = np.mean(X, axis=0)\n",
    "    matrizCovarianza = np.cov(X.T)\n",
    "    return media, matrizCovarianza\n",
    "\n",
    "# Función que calculará para cada observación (con todos sus características) su probabilidad gaussiana conjunta.\n",
    "def obtenerProbabilidadesGaussianas(X, media, matrizCovarianza):\n",
    "    modeloProbabilidad = multivariate_normal(mean=media, cov=matrizCovarianza)\n",
    "    return modeloProbabilidad.pdf(X)\n",
    "\n",
    "# Función que seleccionará mejor límite de probabilidad para detección de anomalías, \n",
    "# tomando como criterio f1-score e información con etiquetas (1=anomalía, 0=normal).\n",
    "def obtenerProbabilidadLimiteParaAnomalias(probabilidades, etiquetas, divisionRangoProbabilidades = 1000):\n",
    "    mejor_epsilon = 0\n",
    "    mejor_f1 = 0\n",
    "    f1 = 0\n",
    "    paso = (max(probabilidades) - min(probabilidades)) / divisionRangoProbabilidades\n",
    "    epsilons = np.arange(min(probabilidades), max(probabilidades), paso)\n",
    "    for epsilon in list(epsilons):\n",
    "        predicciones = (probabilidades < epsilon) \n",
    "        f1 = f1_score(etiquetas, predicciones, average='binary')\n",
    "        if f1 > mejor_f1:\n",
    "            mejor_f1 = f1\n",
    "            mejor_epsilon = epsilon\n",
    "    \n",
    "    return mejor_f1, mejor_epsilon\n",
    "\n",
    "# predecir si los datos son anómalos o no.\n",
    "def predecirDatoAnomalo(X, medias, covarianza, epsilon=0.001):\n",
    "    probabilidades = obtenerProbabilidadesGaussianas(X, medias, covarianza)\n",
    "    predicciones = (probabilidades < epsilon)\n",
    "    return predicciones.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos normales y anómalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaturas para validación: \n",
      "[[ 1.28911641e+00  1.48080075e-02  0.00000000e+00]\n",
      " [-1.68416822e+00  7.84824400e-01  0.00000000e+00]\n",
      " [-1.54901892e+00  1.68811286e-01  0.00000000e+00]\n",
      " [-1.68416822e+00  1.68811286e-01  0.00000000e+00]\n",
      " [-2.12808169e+01  3.38955293e+01  1.00000000e+00]\n",
      " [ 2.34315621e+03 -4.22028215e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos \"normales\", estandarizarlos y etiquetarlos (y=0)\n",
    "estaturasNormales = pd.read_excel('estaturas.xlsx', sheet_name='valtest(normales)')\n",
    "estaturasNormalesEstandarizadas = estaturasScaler.transform(estaturasNormales)\n",
    "estaturasNormalesEstandarizadas = np.c_[estaturasNormalesEstandarizadas, np.zeros(estaturasNormalesEstandarizadas.shape[0])]\n",
    "# Cargar datos \"anómalos\", estandarizarlos y etiquetarlos (y=1)\n",
    "estaturasAnomalas = pd.read_excel('estaturas.xlsx', sheet_name='valtest(anomalias)')\n",
    "estaturasAnomalasEstandarizadas = estaturasScaler.transform(estaturasAnomalas)\n",
    "estaturasAnomalasEstandarizadas = np.c_[estaturasAnomalasEstandarizadas, np.ones(estaturasAnomalasEstandarizadas.shape[0])]\n",
    "# Repartir mitad de datos normales y anómalos en conjuntos de validación y pruebas\n",
    "random.seed(2022)\n",
    "indices = random.sample(range(estaturasNormales.shape[0]), estaturasNormales.shape[0] // 2)\n",
    "normalesValidacion = estaturasNormalesEstandarizadas[indices,:]\n",
    "normalesPruebas = np.array([list(el) for i, el in enumerate(list(estaturasNormalesEstandarizadas)) if i not in set(indices)])\n",
    "random.seed(2022)\n",
    "indices = random.sample(range(estaturasAnomalas.shape[0]), estaturasAnomalas.shape[0] // 2)\n",
    "anomalosValidacion = estaturasAnomalasEstandarizadas[indices,:]\n",
    "anomalosPruebas = np.array([list(el) for i, el in enumerate(list(estaturasAnomalasEstandarizadas)) if i not in set(indices)])\n",
    "estaturasValidacion = np.r_[normalesValidacion, anomalosValidacion]\n",
    "estaturasPruebas = np.r_[normalesPruebas, anomalosPruebas]\n",
    "print('Estaturas para validación: ')\n",
    "print(estaturasValidacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo, validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor epsilon encontrado:  6.901402324377259e-05\n",
      "Mejor f1_score obtenido:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Obtener medias y matriz de covarianza de datos de entrenamiento\n",
    "medias, matrizCovarianza = obtenerMediasyMatrizCovarianza(estaturasEstandarizadas)\n",
    "# Obtener densidades de probabilidad de datos de validación\n",
    "probabilidades = obtenerProbabilidadesGaussianas(estaturasValidacion[:,:-1], medias, matrizCovarianza)\n",
    "# Determinar parámetro límite que mejor detecta anomalías\n",
    "f1, epsilon = obtenerProbabilidadLimiteParaAnomalias(probabilidades, estaturasValidacion[:,-1], 1000)\n",
    "print('Mejor epsilon encontrado: ', epsilon)\n",
    "print('Mejor f1_score obtenido: ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar epsilon en datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score obtenida en datos de prueba:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en datos de prueba\n",
    "predicciones = predecirDatoAnomalo(estaturasPruebas[:,:-1], medias, matrizCovarianza)\n",
    "# Evaluar f1-score de predicciones\n",
    "f1ScorePruebas = f1_score(estaturasPruebas[:,-1], predicciones)\n",
    "print('f1-score obtenida en datos de prueba:')\n",
    "print(f1ScorePruebas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
