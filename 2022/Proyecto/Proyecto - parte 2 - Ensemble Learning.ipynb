{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naked-institution",
   "metadata": {},
   "source": [
    "# Proyecto Final - Ensemble Learning (Aprendizaje por ensamblado)\n",
    "## Parte 2 - Implementación y predicción\n",
    "\n",
    "**Curso:** Statistical Learning\n",
    "\n",
    "**Catedrático:** Ing. Luis Leal\n",
    "\n",
    "**Estudiante:** Dany Rafael Díaz Lux (21000864)\n",
    "\n",
    "**Objetivo:** Hacer clasificación binaria para determinar si una persona sobrevive o no del hundimiento del Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "distributed-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import datetime as dt\n",
    "import joblib\n",
    "#import matplotlib.pylab as plt\n",
    "import numpy as np \n",
    "#import os.path\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import sklearn.metrics as mts\n",
    "#import tensorflow as tf\n",
    "#print('Tensor flow version: ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "patent-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacion de modelos\n",
    "directorioModelos = 'modelos/'\n",
    "extensionModelos = '.modelo'\n",
    "nombreModeloArbolDecision = 'ArbolDecision_criterio=gini_profundidadMaxima=4'\n",
    "nombreModeloSVM = 'SVM_regularizacionC=1.0_kernel=poly_grado=3'\n",
    "nombreParametrosRegresionLogistica = 'RegresionLogisticaMiniBatchGradientDescent_epochs=500_lr=0.01_batchSize=32_alpha=0.0'\n",
    "nombreProbabilidadesNaiveBayes = 'NaiveBayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "provincial-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelos\n",
    "modeloArbolDecision = joblib.load(directorioModelos + nombreModeloArbolDecision + extensionModelos)\n",
    "modeloSVM = joblib.load(directorioModelos + nombreModeloSVM + extensionModelos)\n",
    "parametrosRegresionLogistica = np.load(directorioModelos + nombreParametrosRegresionLogistica + extensionModelos + '.npy')\n",
    "probabilidadesNaiveBayes = dict(np.load(directorioModelos + nombreProbabilidadesNaiveBayes + extensionModelos + '.npy', allow_pickle=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "close-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares para modelo de regresión logística\n",
    "def agregarColumnaUnos(x):\n",
    "    if len(x.shape) < 2:\n",
    "        x = np.array(x, dtype=np.float32).reshape(x.shape[0], -1)\n",
    "    return np.append(x, np.ones(x.shape[0]).reshape(-1,1), 1)\n",
    "\n",
    "def calcularSigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def predecirRegresionLogistica(X, parametros):\n",
    "    X = agregarColumnaUnos(X)\n",
    "    logits = np.matmul(X, parametros)\n",
    "    logits = logits.reshape(logits.shape[0])\n",
    "    return np.round(calcularSigmoid(logits))\n",
    "\n",
    "# Función que indicará si una feature en X es categórica o no\n",
    "def esCategorica(X, indexFeature):\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)\n",
    "        \n",
    "    if(len(np.unique(X[:,indexFeature])) < 11 and\\\n",
    "        len(np.unique(X[:,indexFeature]))/len(X[:,5]) < 0.4):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def predecirNaiveBayes(diccionarioProbabilidades, X):\n",
    "    if(type(X).__module__ != np.__name__):\n",
    "        X = np.array(X)\n",
    "    etiquetas = diccionarioProbabilidades['__labels__']\n",
    "    y_pred = np.zeros(shape=(X.shape[0],1), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        resultados = np.ones_like(etiquetas, dtype=np.float32)\n",
    "        for indiceEtiqueta, etiqueta in enumerate(etiquetas):\n",
    "            resultados[indiceEtiqueta] = diccionarioProbabilidades[str(etiqueta)]\n",
    "            for indiceCaracteristica in range(X.shape[1]):\n",
    "                if(esCategorica(X, indiceCaracteristica)):\n",
    "                    if(str(indiceCaracteristica) + '_' + str(round(X[i,indiceCaracteristica], 10)) + '|' + str(etiqueta) \\\n",
    "                        in diccionarioProbabilidades.keys()):\n",
    "                        resultados[indiceEtiqueta] *= \\\n",
    "                            diccionarioProbabilidades[str(indiceCaracteristica) + '_' + \\\n",
    "                                                      str(round(X[i,indiceCaracteristica], 10)) + '|' + str(etiqueta)]\n",
    "                    else:\n",
    "                        resultados[indiceEtiqueta] = 0.0\n",
    "                        break\n",
    "                # Para características continuas se obtiene la probabilidad del valor (en un rango pequeño) para valor dado\n",
    "                else:\n",
    "                    if('media_' + str(indiceCaracteristica) + '|' + str(etiqueta) \\\n",
    "                        in diccionarioProbabilidades.keys()):\n",
    "                        margen = 0.001\n",
    "                        valorZ = (X[i,indiceCaracteristica] \\\n",
    "                                  - diccionarioProbabilidades['media_' + str(indiceCaracteristica) + '|' + str(etiqueta)])\\\n",
    "                                    / diccionarioProbabilidades['desviacion_' + str(indiceCaracteristica) + '|' + str(etiqueta)]\n",
    "                        probabilidad = st.norm.cdf(valorZ + margen) - st.norm.cdf(valorZ - margen)\n",
    "                        resultados[indiceEtiqueta] *= probabilidad\n",
    "\n",
    "        y_pred[i,0] = etiquetas[np.argmax(resultados)]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "behind-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebas = pd.read_csv(\"datos_validacion_temp.csv\")\n",
    "caracteristicas = pruebas.iloc[:,:-1]\n",
    "etiquetas = pruebas.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "continuous-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8321678321678322\n",
      "0.8095238095238094\n",
      "0.8225806451612904\n",
      "0.796875\n"
     ]
    }
   ],
   "source": [
    "# Revisar métricas de datos de prueba\n",
    "prediccionesArbol = modeloArbolDecision.predict(caracteristicas)\n",
    "print(mts.accuracy_score(etiquetas, prediccionesArbol))\n",
    "print(mts.f1_score(etiquetas, prediccionesArbol))\n",
    "print(mts.precision_score(etiquetas, prediccionesArbol))\n",
    "print(mts.recall_score(etiquetas, prediccionesArbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "limited-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n",
      "0.7936507936507936\n",
      "0.8064516129032258\n",
      "0.78125\n"
     ]
    }
   ],
   "source": [
    "# Revisar métricas de datos de prueba\n",
    "prediccionesSVM = modeloSVM.predict(caracteristicas)\n",
    "print(mts.accuracy_score(etiquetas, prediccionesSVM))\n",
    "print(mts.f1_score(etiquetas, prediccionesSVM))\n",
    "print(mts.precision_score(etiquetas, prediccionesSVM))\n",
    "print(mts.recall_score(etiquetas, prediccionesSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "governmental-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8391608391608392\n",
      "0.8130081300813008\n",
      "0.847457627118644\n",
      "0.78125\n"
     ]
    }
   ],
   "source": [
    "# Revisar métricas de datos de prueba\n",
    "prediccionesRegresion = predecirRegresionLogistica(caracteristicas, parametrosRegresionLogistica)\n",
    "print(mts.accuracy_score(etiquetas, prediccionesRegresion))\n",
    "print(mts.f1_score(etiquetas, prediccionesRegresion))\n",
    "print(mts.precision_score(etiquetas, prediccionesRegresion))\n",
    "print(mts.recall_score(etiquetas, prediccionesRegresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "sixth-culture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762237762237763\n",
      "0.7460317460317459\n",
      "0.7580645161290323\n",
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "# Revisar métricas de datos de prueba\n",
    "prediccionesNaiveBayes = predecirNaiveBayes(probabilidadesNaiveBayes, caracteristicas)\n",
    "print(mts.accuracy_score(etiquetas, prediccionesNaiveBayes))\n",
    "print(mts.f1_score(etiquetas, prediccionesNaiveBayes))\n",
    "print(mts.precision_score(etiquetas, prediccionesNaiveBayes))\n",
    "print(mts.recall_score(etiquetas, prediccionesNaiveBayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-algorithm",
   "metadata": {},
   "source": [
    "## Función de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "respected-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción final combinando los modelos: Árbol de decisión, SVM\n",
    "def prediccionFinal(X):\n",
    "    prediccionesArbolDecision = modeloArbolDecision.predict(X)\n",
    "    prediccionesSVM = modeloSVM.predict(X)\n",
    "    prediccionesRegresionLogistica = predecirRegresionLogistica(X, parametrosRegresionLogistica)\n",
    "    prediccionesNaiveBayes = predecirNaiveBayes(probabilidadesNaiveBayes, X).reshape(X.shape[0])\n",
    "    prediccionTestArbolDecision = 0.8322\n",
    "    prediccionTestSVM = 0.8182\n",
    "    prediccionTestRegresionLogistica = 0.8130\n",
    "    prediccionTestNaiveBayes = 0.7762\n",
    "    totalPrediccion = prediccionTestArbolDecision + prediccionTestSVM + prediccionTestRegresionLogistica + prediccionTestNaiveBayes\n",
    "    pesoArbolDecision =  prediccionTestArbolDecision / totalPrediccion\n",
    "    pesoSVM = prediccionTestSVM / totalPrediccion\n",
    "    pesoRegresionLogistica = prediccionTestRegresionLogistica / totalPrediccion\n",
    "    pesoNaiveBayes = prediccionTestNaiveBayes / totalPrediccion\n",
    "    print(prediccionesArbolDecision.shape, prediccionesSVM.shape, prediccionesRegresionLogistica.shape, prediccionesNaiveBayes.shape)\n",
    "    prediccionFinal = pesoArbolDecision * prediccionesArbolDecision \\\n",
    "                    + pesoSVM * prediccionesSVM \\\n",
    "                    + pesoRegresionLogistica * prediccionesRegresionLogistica \\\n",
    "                    + pesoNaiveBayes * prediccionesNaiveBayes\n",
    "    return np.round(prediccionFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "measured-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143,) (143,) (143,) (143,)\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "0.8251748251748252\n",
      "0.8\n",
      "0.819672131147541\n",
      "0.78125\n"
     ]
    }
   ],
   "source": [
    "# Revisar métricas de datos de prueba\n",
    "prediccionesFinales = prediccionFinal(caracteristicas)\n",
    "print(prediccionesFinales)\n",
    "print(mts.accuracy_score(etiquetas, prediccionesFinales))\n",
    "print(mts.f1_score(etiquetas, prediccionesFinales))\n",
    "print(mts.precision_score(etiquetas, prediccionesFinales))\n",
    "print(mts.recall_score(etiquetas, prediccionesFinales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "personal-attitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloNaiveBayes = np.load('test.npy', allow_pickle=True)\n",
    "#diccTest = dict(enumerate(modeloNaiveBayes[0].flatten(), 1))[1]\n",
    "#diccTest['0_0']\n",
    "modeloNaiveBayes[0]['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-miller",
   "metadata": {},
   "source": [
    "## Predicción árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-console",
   "metadata": {},
   "source": [
    "## Predicción Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-minute",
   "metadata": {},
   "source": [
    "## Predicción Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-exchange",
   "metadata": {},
   "source": [
    "## Predicción regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-millennium",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
